# Bedrock Agent Test Bed with Knowledge Base

A simple, focused test environment for AWS Bedrock that demonstrates how to use Terraform to create a Bedrock agent with a small Knowledge Base to supplement the model with information available about a given city.  Users provide a city name, and Bedrock returns 10 interesting facts by combining:
- **General knowledge** from Claude 3.5 Haiku foundation model
- **Real-world data** from a knowledge base (air quality, water pollution, cost of living, and others)
- **Action groups** that invoke Lambda functions for additional processing

This project showcases two approaches: direct model access and agent-based architecture with knowledge base integration using OpenSearch Serverless vector storage.

**Testing**: This is a backend-focused project. Testing is currently done by directly invoking Lambda functions via AWS CLI. No front-end interface exists at this time.

![Bedrock Architecture Comparison](./docs/bedrock-full-comparison.png)

## ğŸ¯ What This Demonstrates

**Input**: City name (e.g., "Geneva", "Tokyo", "Berlin")

**Output**: 10 key facts about the city including:
- Historical significance and founding
- Cultural landmarks and traditions
- Environmental data (air quality, water pollution) from knowledge base
- Economic information (cost of living) from knowledge base
- Population, geography, and interesting trivia

**Key AWS Services**:
- AWS Bedrock (Claude 3.5 Haiku model)
- Bedrock Agents with Action Groups
- Bedrock Knowledge Base with vector search
- OpenSearch Serverless for vector storage
- Lambda functions for custom logic
- S3 for knowledge base data storage

### ğŸ’¡ Vector Storage Note

This project uses **OpenSearch Serverless** for vector storage because it's simple to set up and fully managed. However, it can be **expensive**:
- **Dev/Test** (1 OCU, no redundancy): ~$175/month
- **Production** (2 OCUs with redundancy): ~$350/month minimum
- **Production** (4 OCUs with redundancy): ~$700/month

**For Bedrock RAG systems, consider these Bedrock-supported alternatives:**

**AWS Native Options:**
- **Amazon Aurora PostgreSQL with pgvector** - Cost-effective, familiar SQL interface, fully supported
- **Amazon Neptune Analytics** - Graph database with vector search capabilities

**Third-Party Options (Bedrock-Supported):**
- **Pinecone** - Purpose-built vector database, pay-per-use pricing
- **MongoDB Atlas** - Document database with vector search
- **Redis Enterprise** - In-memory database with vector capabilities

---

## ğŸš€ Quick Start

If you're up to speed on Git, Terraform, and AWS CLI and setting its credentials, then follow these steps for a complete deployment in ~10 minutes.

**[ğŸ“„ Quick Start Guide â†’](docs/DEPLOYMENT.md)**

The Quick Start guide includes:
- Prerequisites checklist
- One-command deployment
- Testing instructions
- Teardown commands

---

## ğŸ“š Table of Contents

- [Architecture Overview](#ï¸-architecture-overview)
- [Deployment and Teardown](#-deployment-and-teardown)
- [Testing](#-testing)
- [API Documentation](#-api-documentation)
- [Development Workflow](#ï¸-development-workflow)
- [Project Structure](#-project-structure)
- [Troubleshooting](#-troubleshooting)

## ğŸ—ï¸ Architecture Overview

This project demonstrates **two distinct approaches** to using AWS Bedrock for generating city information:

### Approach 1: Direct Model Access (Simple)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Input    â”‚
â”‚ {"city":"Tokyo"}â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Lambda Direct (lambda_direct)                   â”‚
â”‚  â€¢ Receives city name                                   â”‚
â”‚  â€¢ Constructs prompt                                    â”‚
â”‚  â€¢ Calls bedrock-runtime.invoke_model()                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Claude 3.5 Haiku Foundation Model               â”‚
â”‚  â€¢ Processes prompt                                     â”‚
â”‚  â€¢ Generates 10 city facts using large language model   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response      â”‚
â”‚ â€¢ 10 facts      â”‚
â”‚ â€¢ General info  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Approach 2: Agent-Based with Knowledge Base (Advanced)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Input    â”‚
â”‚{"city":"Geneva"}â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Lambda Agent (lambda_agent)                     â”‚
â”‚  â€¢ Receives city name                                   â”‚
â”‚  â€¢ Constructs detailed prompt                           â”‚
â”‚  â€¢ Calls bedrock-agent-runtime.invoke_agent()           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Bedrock Agent (Claude 3.5 Haiku)                â”‚
â”‚  â€¢ Orchestrates multiple data sources                   â”‚
â”‚  â€¢ Plans response strategy                              â”‚
â”‚  â€¢ Decides which tools to use based on prompt           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚
          â”‚                   â–¼
          â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        â”‚     Knowledge Base               â”‚
          â”‚        â”‚  (OpenSearch Serverless)         â”‚
          â”‚        â”‚                                  â”‚
          â”‚        â”‚ â€¢ Vector search for city data    â”‚
          â”‚        â”‚ â€¢ Air quality (500+ cities)      â”‚
          â”‚        â”‚ â€¢ Water pollution metrics        â”‚
          â”‚        â”‚ â€¢ Cost of living (400+ cities)   â”‚
          â”‚        â”‚ â€¢ Associated with agent          â”‚
          â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚
          â”‚                   â–¼
          â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        â”‚   S3 Bucket      â”‚
          â”‚        â”‚ â€¢ CSV datasets   â”‚
          â”‚        â”‚ â€¢ Vector indexed â”‚
          â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Action Group: /city-facts API (Internal)             â”‚
â”‚  â€¢ Agent calls POST /city-facts internally              â”‚
â”‚  â€¢ Defined by OpenAPI spec in agent config              â”‚
â”‚  â€¢ Executor: lambda_direct function                     â”‚
â”‚  â€¢ NOT called directly by users                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Lambda Direct (as Action Group)                 â”‚
â”‚  â€¢ Invoked by agent via action group                    â”‚
â”‚  â€¢ Gets general city facts from model                   â”‚
â”‚  â€¢ Returns structured data to agent                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Agent Synthesizes Response                      â”‚
â”‚  â€¢ Combines knowledge base data                         â”‚
â”‚  â€¢ Integrates action group results                      â”‚
â”‚  â€¢ Generates coherent narrative                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response      â”‚
â”‚ â€¢ 10 facts      â”‚
â”‚ â€¢ KB data       â”‚
â”‚ â€¢ General info  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Differences

| Feature | Direct Model Access | Agent-Based |
|---------|-------------------|-------------|
| **Lambda Function** | `lambda_direct` | `lambda_agent` |
| **Bedrock API** | `invoke_model()` | `invoke_agent()` |
| **Data Sources** | Large language model only | Model + Knowledge Base + Action Groups |
| **Complexity** | Simple, single API call | Orchestrated, multi-source |
| **Knowledge Base** | âŒ No | âœ… Yes (OpenSearch, associated with agent) |
| **Action Groups** | âŒ No | âœ… Yes (`/city-facts` API, internal only) |
| **Real-time Data** | âŒ No | âœ… Yes (from CSV datasets) |
| **Use Case** | Baseline testing | Full Bedrock capabilities |
| **API Invocation** | Direct Lambda call | Agent orchestrates internal APIs |

### How Each Approach Works

**Direct Model Access:**
1. User provides city name â†’ `{"city": "Tokyo"}`
2. Lambda constructs prompt â†’ "Provide 10 facts about Tokyo"
3. Calls Bedrock Runtime â†’ `invoke_model()` with Claude 3.5 Haiku
4. Model generates response â†’ Using large language model
5. Returns 10 facts â†’ General knowledge only

**Agent-Based:**
1. User provides city name â†’ `{"city": "Geneva"}`
2. Lambda constructs prompt â†’ "Tell me about Geneva, including air quality, water pollution, and cost of living"
3. Calls Bedrock Agent â†’ `invoke_agent()` 
4. Agent orchestrates (automatically decides which tools to use):
   - **Knowledge Base Search** â†’ Agent queries OpenSearch for Geneva data (air quality, water pollution, cost of living)
     - Knowledge base is **associated with the agent** via Terraform configuration
     - Agent has IAM permissions to call `bedrock:Retrieve`
   - **Action Group Call** â†’ Agent internally calls `POST /city-facts` API
     - This API is defined in the agent's OpenAPI specification
     - The API is **not called directly by users** - only by the agent
     - Executor is `lambda_direct` function
     - Returns general city facts from the model
5. Agent synthesizes â†’ Combines knowledge base data + action group results
6. Returns comprehensive response â†’ KB data + general facts

**Key Insight**: The `/city-facts` API is an **internal tool** for the agent. Users never call it directly - they call `lambda_agent`, which invokes the Bedrock Agent, which then decides to use the `/city-facts` action group as one of its tools.

## ğŸš€ Deployment and Teardown

For complete deployment instructions, teardown options, and step-by-step guides, see:

**[ğŸ“„ Deployment and Teardown Guide](docs/DEPLOYMENT.md)**

The deployment guide includes:
- **Simplified Deployment** - One-command deployment (recommended)
- **Resource Prefixing** - Multi-developer environment support
- **Manual Deployment** - Step-by-step instructions for advanced users
- **Complete Teardown** - Remove all resources and avoid charges
- **Partial Teardown** - Infrastructure-only or S3-only cleanup options
- **Cost Information** - Detailed cost implications and redeployment instructions

## ğŸ§ª Testing

### ğŸš€ Quick Testing with Scripts

The testing scripts automatically detect your resource prefix and use the correct function names:

```bash
# Test both direct and agent-based approaches with cities that have complete data
./test-lambda.sh both Geneva

# Test specific functions with knowledge base cities
./test-lambda.sh direct Berlin
./test-lambda.sh agent "Zurich"

# Use development workflow helper with recommended cities
./scripts/dev-workflow.sh test Basel
```

### ğŸ¯ Automatic Prefix Detection

All scripts automatically detect your prefix from `terraform.tfvars`:

```bash
# If terraform.tfvars contains: resource_prefix = "dts"
./test-lambda.sh both Geneva
# â†’ Tests: dts-bedrock-agent-testbed-city-facts-direct
# â†’ Tests: dts-bedrock-agent-testbed-city-facts-agent

# Without prefix
./test-lambda.sh both Geneva  
# â†’ Tests: bedrock-agent-testbed-city-facts-direct
# â†’ Tests: bedrock-agent-testbed-city-facts-agent
```

## ğŸ“– API Documentation

### Complete API Specification

For comprehensive API documentation including OpenAPI specifications, request/response examples, and integration patterns, see:

**[ğŸ“„ docs/API.md](docs/API.md)**

The API documentation includes:
- **OpenAPI 3.0 Specification** for the City Facts Action Group API
- **Request/Response Examples** for both Lambda functions
- **Error Handling** patterns and common error codes
- **Integration Examples** in Python and Node.js
- **Usage Patterns** for different testing scenarios
- **Rate Limits and Best Practices**

### Quick API Reference

#### Lambda Direct (Simple Model Access)

**Input**:
```json
{"city": "Tokyo"}
```

**Output**:
```json
{
  "city": "Tokyo",
  "facts": ["fact 1", "fact 2", ...],
  "total_facts": 10,
  "message": "Here are facts about Tokyo generated by Claude 3 Haiku!",
  "model_used": "anthropic.claude-3-haiku-20240307-v1:0"
}
```

#### Lambda Agent (Agent-Based with Knowledge Base)

**Input**:
```json
{"city": "Geneva"}
```

**Output**:
```json
{
  "city": "Geneva",
  "agent_response": "Here is what I can share about Geneva:\n\nBased on the search results, Geneva has an air quality index of 20.17...",
  "message": "City facts for Geneva generated via Bedrock Agent",
  "agent_id": "137GJDIGTS",
  "session_id": "unique-session-id",
  "source": "bedrock_agent"
}
```

### Testing Commands

```bash
# Test direct Lambda
aws lambda invoke \
  --function-name bedrock-agent-testbed-city-facts-direct \
  --cli-binary-format raw-in-base64-out \
  --payload '{"city": "Tokyo"}' \
  response.json

# Test agent Lambda
aws lambda invoke \
  --function-name bedrock-agent-testbed-city-facts-agent \
  --cli-binary-format raw-in-base64-out \
  --payload '{"city": "Geneva"}' \
  response.json
```

### Manual Testing Examples

#### Test Direct Model Access
```bash
aws lambda invoke \
  --function-name bedrock-agent-testbed-city-facts-direct \
  --cli-binary-format raw-in-base64-out \
  --payload '{"city": "Berlin"}' \
  response_direct.json
```

#### Test Agent with Knowledge Base
```bash
aws lambda invoke \
  --function-name bedrock-agent-testbed-city-facts-agent \
  --cli-binary-format raw-in-base64-out \
  --payload '{"city": "Geneva"}' \
  response_agent.json
```

#### Test Cities with Knowledge Base Data

The knowledge base contains two datasets with extensive city coverage:

**ğŸŒŸ Recommended Test Cities (Complete Data in Both Datasets):**
These cities have both air quality/water pollution AND cost of living data, providing the richest agent responses:

- **Geneva, Switzerland** - High cost of living, excellent air quality
- **Zurich, Switzerland** - Premium living costs, clean environment  
- **Basel, Switzerland** - Swiss quality with complete datasets
- **Berlin, Germany** - European capital with moderate costs
- **London, United Kingdom** - Global financial center
- **Paris, France** - Cultural capital with urban challenges
- **Boston, USA** - American tech hub with good data
- **Chicago, USA** - Major US city with comprehensive info
- **Los Angeles, USA** - West Coast metropolis
- **Montreal, Canada** - Bilingual city with full datasets

**ğŸŒ Additional Cities with Complete Data:**
Athens, Bangkok, Barcelona, Beijing, Bern, Brussels, Buenos Aires, Delhi, Dubai, Dublin, Helsinki, Lisbon, Madrid, Milan, Miami, Moscow, Mumbai, Oslo

**ğŸ“Š Dataset Coverage:**
- **Air Quality & Water Pollution**: 500+ cities worldwide (2021 data)
- **Cost of Living**: 400+ cities worldwide (2018 data)  
- **Both Datasets**: 200+ cities with complete information

**ğŸ§ª Testing Examples:**
```bash
# Cities with rich knowledge base data
./test-lambda.sh agent "Geneva"
./test-lambda.sh agent "Berlin" 
./test-lambda.sh agent "Tokyo"

# Compare different data availability
./test-lambda.sh both "Geneva"    # Complete data from both sources
./test-lambda.sh both "Singapore" # Partial data, general facts
```

**ğŸ’¡ Pro Tip:** Cities with data in both datasets will provide more comprehensive responses as the agent can combine air quality, water pollution, and cost of living information with general city facts.

## ğŸ“Š Current Components

### Lambda Functions
- **Direct**: `bedrock-agent-testbed-city-facts-direct` - Direct Claude 3 Haiku access
- **Agent**: `bedrock-agent-testbed-city-facts-agent` - Bedrock agent integration

### Bedrock Agent
- **Agent ID**: Retrieved from Terraform output
- **Model**: Claude 3 Haiku (`anthropic.claude-3-haiku-20240307-v1:0`)
- **Action Groups**: CityFactsActionGroup (invokes direct Lambda)
- **Knowledge Base**: Integrated with OpenSearch Serverless

### Knowledge Base
- **Vector Store**: OpenSearch Serverless
- **Embedding Model**: Amazon Titan Text Embeddings
- **Data Sources**: 
  - World cities air quality and water pollution (2021)
  - World cities cost of living (2018)

## ğŸ“Š Knowledge Base Data Sources

This project uses real-world datasets sourced from **[Kaggle](https://www.kaggle.com)** to demonstrate knowledge base functionality:

### Air Quality & Water Pollution Dataset (2021)
- **Coverage**: 500+ cities worldwide
- **Metrics**: Air Quality Index, Water Pollution Index
- **Format**: CSV with city, region, country, and pollution metrics
- **Use Case**: Environmental data for city comparisons

### Cost of Living Dataset (2018)
- **Coverage**: 400+ cities worldwide
- **Metrics**: Cost of Living Index, Rent Index, Groceries Index, Restaurant Price Index
- **Format**: CSV with comprehensive economic indicators
- **Use Case**: Economic data for lifestyle and affordability insights

### Data Processing
- **Purpose**: Educational and demonstration use in this Bedrock Agent test environment
- **Processing**: Data is chunked and vectorized using Amazon Titan embeddings for semantic search
- **Integration**: Accessible via Bedrock Agent through OpenSearch Serverless vector database

## ğŸ› ï¸ Development Workflow

### ğŸš€ Simplified Workflow with Terraform-Managed S3

The new approach eliminates most manual steps:

```bash
# Complete deployment (includes S3, files, and knowledge base)
./scripts/deploy-complete.sh dts

# Update Lambda code only (auto-detects prefix)
./scripts/deploy-lambda.sh

# Test functions (auto-detects prefix)  
./test-lambda.sh both Geneva

# Check deployment status (shows all resources with prefix)
./scripts/dev-workflow.sh status

# View logs (auto-detects function names)
./scripts/dev-workflow.sh logs-direct
./scripts/dev-workflow.sh logs-agent
```

### ğŸ”„ Quick Lambda Updates (No Terraform)

For rapid development iterations:
```bash
# Deploy both functions (auto-detects prefix from terraform.tfvars)
./deploy-lambda.sh

# Deploy specific function
./deploy-direct.sh      # Direct model access only
./deploy-agent.sh       # Agent-based only
```

### ğŸ“Š Development Helper Commands

```bash
# Show comprehensive status (all resources with your prefix)
./scripts/dev-workflow.sh status

# Test with recommended cities
./scripts/dev-workflow.sh test Geneva
./scripts/dev-workflow.sh test-agent Berlin

# View recent logs
./scripts/dev-workflow.sh logs-direct
./scripts/dev-workflow.sh logs-agent

# Quick Terraform operations
./scripts/dev-workflow.sh terraform
```

### ğŸ—‚ï¸ Legacy S3 Management (External Buckets)

For existing deployments using external S3 buckets:
```bash
# Setup S3 bucket and upload data
./scripts/dev-workflow.sh setup-kb-s3

# Check knowledge base status
./scripts/dev-workflow.sh check-kb-s3

# Clean up (if needed)
./scripts/dev-workflow.sh cleanup-kb-s3
```

### Infrastructure Changes
```bash
# For infrastructure changes
terraform plan
terraform apply
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ terraform/                        # ğŸ—ï¸ Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf                       # Main Terraform configuration with prefix support
â”‚   â”œâ”€â”€ lambda.tf                     # Lambda functions and IAM (prefix-aware)
â”‚   â”œâ”€â”€ bedrock_agent.tf              # Bedrock agent configuration (prefix-aware)
â”‚   â”œâ”€â”€ bedrock_knowledge_base_simple.tf # Knowledge base with Terraform-managed S3
â”‚   â”œâ”€â”€ outputs.tf                    # Terraform outputs (prefix-aware)
â”‚   â”œâ”€â”€ terraform.tfvars              # ğŸ”§ Your personal config (git-ignored, prefix settings)
â”‚   â”œâ”€â”€ terraform.tfvars.example      # ğŸ“‹ Example configuration file
â”‚   â”œâ”€â”€ terraform.tfstate             # âš ï¸ CRITICAL: Infrastructure state (DO NOT DELETE)
â”‚   â””â”€â”€ .terraform/                   # Terraform working directory
â”œâ”€â”€ scripts/                          # ğŸ› ï¸ Deployment and Management Scripts
â”‚   â”œâ”€â”€ deploy-complete.sh            # ğŸš€ Complete automated deployment (NEW)
â”‚   â”œâ”€â”€ deploy-lambda.sh              # Deploy Lambda functions (prefix-aware)
â”‚   â”œâ”€â”€ deploy-direct.sh              # Deploy direct model Lambda only
â”‚   â”œâ”€â”€ deploy-agent.sh               # Deploy agent Lambda only
â”‚   â”œâ”€â”€ build.sh                      # Build Lambda packages
â”‚   â”œâ”€â”€ test-lambda.sh                # ğŸ§ª Testing script (prefix-aware)
â”‚   â”œâ”€â”€ dev-workflow.sh               # ğŸ› ï¸ Development helper (prefix-aware)
â”‚   â”œâ”€â”€ teardown-complete.sh          # ğŸ”¥ Complete infrastructure teardown
â”‚   â”œâ”€â”€ teardown-infrastructure.sh    # ğŸ—ï¸ Infrastructure-only teardown
â”‚   â”œâ”€â”€ teardown-s3-only.sh           # ğŸª£ S3 data teardown
â”‚   â”œâ”€â”€ import-existing-resources.sh  # ğŸ†˜ State recovery script (prefix-aware)
â”‚   â”œâ”€â”€ setup-knowledge-base-s3.sh    # ğŸ“¦ Legacy S3 setup (external buckets)
â”‚   â””â”€â”€ check-knowledge-base-s3.sh    # ğŸ” Check S3 status
â”œâ”€â”€ src/                              # ğŸ’» Lambda Source Code
â”‚   â”œâ”€â”€ lambda_direct/
â”‚   â”‚   â””â”€â”€ index.py                  # Direct model access Lambda
â”‚   â””â”€â”€ lambda_agent/
â”‚       â””â”€â”€ index.py                  # Agent-based Lambda
â”œâ”€â”€ data/                             # ğŸ“Š Test Data and Knowledge Base Content
â”‚   â”œâ”€â”€ lambda-tests/                 # Test payloads
â”‚   â”‚   â”œâ”€â”€ direct-*.json
â”‚   â”‚   â”œâ”€â”€ agent-*.json
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ knowledge-base/               # Knowledge base source data
â”‚       â”œâ”€â”€ world_cities_air_quality_water_pollution_2021.csv
â”‚       â”œâ”€â”€ world_cities_cost_of_living_2018.csv
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ docs/                             # ğŸ“– Documentation
â”‚   â”œâ”€â”€ API.md                        # Complete API documentation with OpenAPI specs
â”‚   â””â”€â”€ bedrock-full-comparison.png   # Architecture diagram
â”œâ”€â”€ .kb-bucket-name                   # ğŸ“ S3 bucket name reference (legacy)
â”œâ”€â”€ *.zip                             # Generated Lambda packages (git-ignored)
â”œâ”€â”€ test_*.json                       # Generated test results (git-ignored)
â””â”€â”€ README.md                         # This file
```

### ğŸ”‘ Key Files and Folders

**ğŸ“ terraform/** - Infrastructure as Code
- All Terraform configuration files
- Your personal `terraform.tfvars` settings (optional - has defaults)
- **CRITICAL**: `terraform.tfstate` file (never delete!)

**ğŸ“ scripts/** - Automation and Management
- All deployment, testing, and teardown scripts
- Auto-detect resource prefixes from terraform.tfvars
- Run from project root: `./scripts/deploy-complete.sh`

**ğŸ“ src/** - Lambda Source Code
- Organized by function type
- `lambda_direct/` - Direct model access
- `lambda_agent/` - Agent-based approach

**ğŸ“ data/** - Test Data and Knowledge Base
- `lambda-tests/` - JSON payloads for testing
- `knowledge-base/` - CSV files for vector database

**ğŸ“ docs/** - Documentation
- `API.md` - Complete API documentation with OpenAPI specifications
- `bedrock-full-comparison.png` - Architecture diagram

### ğŸš€ Quick Start Commands

```bash
# Complete deployment (from project root)
./scripts/deploy-complete.sh dts

# Update Lambda code only
./scripts/deploy-lambda.sh

# Test functions
./scripts/test-lambda.sh both Geneva

# Development workflow helper
./scripts/dev-workflow.sh status

# Terraform operations
cd terraform && terraform plan && cd ..

# Complete teardown
./scripts/teardown-complete.sh
```

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. OpenSearch Vector Index Creation (New Deployment Process)
**Problem**: Knowledge base creation fails with "no such index [bedrock-knowledge-base-default-index]"
**Solution**: The deployment process now handles this automatically, but if you encounter issues:

```bash
# Get collection ID from Terraform output
COLLECTION_ID=$(terraform output -raw opensearch_collection_id)

# Create the vector index manually
aws opensearchserverless create-index \
  --id "$COLLECTION_ID" \
  --index-name "bedrock-knowledge-base-default-index" \
  --index-schema '{
    "settings": {"index": {"knn": true}},
    "mappings": {
      "properties": {
        "embeddings": {
          "type": "knn_vector",
          "dimension": 1536,
          "method": {"name": "hnsw", "space_type": "l2", "engine": "faiss"}
        },
        "text": {"type": "text"},
        "bedrock-metadata": {"type": "text"}
      }
    }
  }' \
  --region us-east-1
```

**Root Cause**: OpenSearch Serverless requires the vector index to exist before knowledge base creation
**Prevention**: Use the complete deployment script which handles this automatically

#### 2. S3 Bucket Not Empty During Teardown
**Problem**: `terraform destroy` fails with "BucketNotEmpty" error
**Solution**: This is now handled automatically by the teardown script, but if you encounter it:

```bash
# The teardown script now automatically empties buckets, but manual cleanup:
BUCKET_NAME=$(terraform output -raw s3_knowledge_base_bucket)
aws s3 rm s3://$BUCKET_NAME --recursive
aws s3api delete-objects --bucket $BUCKET_NAME \
  --delete "$(aws s3api list-object-versions --bucket $BUCKET_NAME \
  --query '{Objects: Versions[].{Key: Key, VersionId: VersionId}}' --output json)"
```

**Root Cause**: S3 buckets with versioning enabled require all versions to be deleted
**Prevention**: Use `./scripts/teardown-complete.sh` which handles this automatically

#### 3. OpenSearch Access Denied
**Problem**: "Access denied to create index" or "403 Forbidden" when accessing OpenSearch
**Solution**: Check your OpenSearch access configuration:

```bash
# Verify your current AWS identity
aws sts get-caller-identity

# Check if include_current_user_in_opensearch_access is enabled
grep include_current_user_in_opensearch_access terraform/terraform.tfvars

# If not set, add it to terraform.tfvars:
echo "include_current_user_in_opensearch_access = true" >> terraform/terraform.tfvars
terraform apply
```

**Root Cause**: OpenSearch access policy doesn't include your current user
**Prevention**: The default configuration now includes current user automatically

#### 4. Lambda Environment Variables Missing
**Problem**: Agent Lambda function fails with "BEDROCK_AGENT_ID environment variable not set"
**Solution**: This is now handled automatically, but if you encounter it:

```bash
# Check if Lambda has environment variables
aws lambda get-function-configuration \
  --function-name $(terraform output -raw lambda_function_agent_name) \
  --query 'Environment.Variables'

# If missing, redeploy the Lambda function
./scripts/deploy-lambda.sh
```

**Root Cause**: Lambda function missing dynamic environment variables
**Prevention**: Use the latest deployment scripts which set environment variables automatically

#### 5. Lost Terraform State File
**Problem**: Accidentally deleted `terraform.tfstate` file
**Solution**: Use the provided import script to recover state from existing AWS resources
```bash
./scripts/import-existing-resources.sh
```
This script will:
- Detect your existing S3 bucket
- Import all deployed resources back into Terraform state
- Recreate `terraform.tfvars` and `.kb-bucket-name` files
- Verify the import with `terraform plan`

#### 6. Missing terraform.tfvars File
**Problem**: `terraform plan` fails with "no file exists at .kb-bucket-name"
**Solution**: 
```bash
# Option 1: Run the S3 setup script (creates terraform.tfvars automatically)
./scripts/setup-knowledge-base-s3.sh

# Option 2: Create terraform.tfvars manually with your existing bucket name
echo 'knowledge_base_bucket_name = "your-bucket-name"' > terraform/terraform.tfvars
```

#### 7. OpenSearch Index Creation Fails (Legacy)
**Problem**: "Access denied to create index" in AWS Console
**Solution**: The manual CLI approach is required due to OpenSearch Serverless permissions

#### 8. Knowledge Base Creation Fails (Legacy)
**Problem**: "no such index [bedrock-knowledge-base-default-index]"
**Solution**: Ensure Step 4 (manual index creation) is completed before running terraform apply

#### 9. Agent Access Denied to Knowledge Base
**Problem**: "Access denied when calling Bedrock KnowledgeBase retrieve"
**Solution**: Ensure the agent IAM role has `bedrock:Retrieve` permission (included in Terraform)

#### 10. Ingestion Jobs Fail
**Problem**: Ingestion jobs fail or show 0 documents processed
**Solution**: 
- Verify S3 bucket permissions
- Check CSV file format and location
- Ensure knowledge base role has S3 access

#### 11. Stuck Resources During Teardown
**Problem**: `terraform destroy` fails with resource dependencies or timeouts
**Solution**:
```bash
# Try destroying specific resource types first
terraform destroy -target=aws_bedrockagent_agent_knowledge_base_association.city_facts_kb_association_simple
terraform destroy -target=aws_bedrockagent_data_source.air_quality_data_simple
terraform destroy -target=aws_bedrockagent_data_source.cost_of_living_data_simple

# Then destroy the rest
terraform destroy
```

#### 12. OpenSearch Collection Won't Delete
**Problem**: OpenSearch Serverless collection deletion hangs or fails
**Solution**: 
- Wait 10-15 minutes (OpenSearch deletions are slow)
- Check AWS console for collection status
- Manually delete from console if Terraform fails

### Verification Commands
```bash
# Check OpenSearch collection status
aws opensearchserverless list-collections --region us-east-1

# Check knowledge base status
aws bedrock-agent list-knowledge-bases --region us-east-1

# Check ingestion job status
aws bedrock-agent list-ingestion-jobs \
  --knowledge-base-id YOUR_KB_ID \
  --data-source-id YOUR_DS_ID \
  --region us-east-1
```

## ğŸ“ˆ Example Responses

### Agent Response with Knowledge Base Data
```json
{
  "city": "New York City",
  "agent_response": "According to the search results, the air quality index for New York City is 46.82 and the water pollution index is 49.50. The city is known for its diverse economy, iconic landmarks like the Statue of Liberty and Central Park, and serves as a major financial center...",
  "message": "City facts for New York City generated via Bedrock Agent",
  "agent_id": "1DSXPQRXQJ",
  "session_id": "unique-session-id",
  "requested_city": "New York City",
  "source": "bedrock_agent"
}
```

## ğŸ¯ Features

âœ… **Direct Bedrock Integration**: Lambda function with Claude 3 Haiku  
âœ… **Bedrock Agent**: Complete agent with action groups  
âœ… **Knowledge Base**: OpenSearch Serverless with vector embeddings  
âœ… **Dual Data Sources**: Air quality and cost of living data  
âœ… **Automated Ingestion**: CSV data processing and vectorization  
âœ… **Comprehensive IAM**: Proper permissions for all components  
âœ… **Development Tools**: Scripts for rapid deployment and testing  
âœ… **Error Handling**: Graceful handling of missing data  
âœ… **Internal Action Group API**: `/city-facts` API for agent orchestration (not user-facing)

### ğŸ”‘ Key Architectural Concepts

**Knowledge Base Association**: The knowledge base is associated with the Bedrock Agent via Terraform, giving the agent automatic access to search it. The `lambda_direct` function does not have direct knowledge base access - only the agent does.

**Action Group API**: The `/city-facts` API is an internal tool defined in the agent's OpenAPI specification. Users never call it directly - only the Bedrock Agent calls it as part of its orchestration process.

**Two Invocation Paths**:
- **Direct**: User â†’ `lambda_direct` â†’ Model â†’ Response (no KB)
- **Agent**: User â†’ `lambda_agent` â†’ Agent â†’ (KB search + `/city-facts` call) â†’ Synthesized Response  

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines on how to contribute to this project.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”® Next Steps

- [ ] Add front-end interface (Streamlit, React, etc) with API Gateway integration to provide a user-friendly UI for querying city facts
- [ ] Implement Bedrock Guardrails to filter inappropriate content and enforce safety policies
- [ ] Explore multi-agent architecture where specialized agents handle different aspects (e.g., one for environmental data, one for cultural facts, etc)
- [ ] Add more data sources to knowledge base
- [ ] Implement conversation memory
- [ ] Create additional action groups
- [ ] Add monitoring and alerting
- [ ] Implement automated testing pipeline

## ğŸ“ Notes

- **Region**: All resources deployed in `us-east-1`
- **Model**: Claude 3 Haiku for cost-effective testing
- **Vector Store**: OpenSearch Serverless for managed vector search
- **Embeddings**: Amazon Titan Text Embeddings (1536 dimensions)
- **Manual Step**: OpenSearch index creation required due to permissions

## ğŸš€ Quick Reference

### ğŸ¯ New Deployment (Terraform-Managed S3)
```bash
# ğŸ—ï¸ Deploy everything with prefix
./deploy-complete.sh dts

# ğŸ§ª Test functions (auto-detects prefix)
./test-lambda.sh both Geneva

# ğŸ”„ Update Lambda code only
./deploy-lambda.sh

# ğŸ“Š Check infrastructure status
./scripts/dev-workflow.sh status

# ğŸ”¥ Complete teardown
./scripts/teardown-complete.sh
```

### ğŸ› ï¸ Development Operations
```bash
# ğŸ”§ Build Lambda packages
./build.sh

# ğŸš€ Deploy functions (auto-detects prefix)
./deploy-lambda.sh
./deploy-direct.sh
./deploy-agent.sh

# ğŸ§ª Test with recommended cities
./scripts/test-lambda.sh both Geneva
./scripts/dev-workflow.sh test Berlin

# ğŸ“‹ View logs (auto-detects function names)
./scripts/dev-workflow.sh logs-direct
./scripts/dev-workflow.sh logs-agent

# ğŸ“Š Infrastructure operations
cd terraform && terraform plan && cd ..
cd terraform && terraform apply && cd ..
./scripts/dev-workflow.sh terraform
```

### ğŸ—‚ï¸ Legacy Operations (External S3)
```bash
# ğŸ“¦ Setup external S3 bucket
./scripts/setup-knowledge-base-s3.sh dts

# ğŸ” Check S3 status
./scripts/check-knowledge-base-s3.sh

# ğŸ§¹ S3 cleanup only
./scripts/teardown-s3-only.sh
```

### ğŸ”¥ Teardown Options
```bash
# Scenario 1: Done with project permanently
./scripts/teardown-complete.sh

# Scenario 2: Pause project, keep data
./scripts/teardown-infrastructure.sh

# Scenario 3: Clean data, keep infrastructure  
./scripts/teardown-s3-only.sh

# Scenario 4: Emergency cleanup
terraform destroy
aws s3 rm s3://bucket-name --recursive
aws s3 rb s3://bucket-name
```

### File Management
```bash
# Important files to backup
terraform.tfstate      # Infrastructure state
terraform.tfvars       # Configuration variables
.kb-bucket-name        # S3 bucket reference

# Generated files (safe to delete)
*.zip                  # Lambda packages
test_*.json           # Test responses
.terraform/           # Terraform cache
```