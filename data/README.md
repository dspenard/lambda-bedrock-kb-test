# Data Directory

This directory contains all data files used by the Bedrock Agent Test Bed project, organized by purpose and usage.

## ğŸ“ Folder Structure

```
data/
â”œâ”€â”€ knowledge-base/          # ğŸ§  Knowledge Base Source Data
â”‚   â”œâ”€â”€ world_cities_air_quality_water_pollution_2021.csv
â”‚   â”œâ”€â”€ world_cities_cost_of_living_2018.csv
â”‚   â”œâ”€â”€ world-cities-overview.md
â”‚   â””â”€â”€ README.md
â””â”€â”€ lambda-tests/           # ğŸ§ª Lambda Function Test Payloads
    â”œâ”€â”€ agent-*.json        # Test payloads for agent-based Lambda
    â”œâ”€â”€ direct-*.json       # Test payloads for direct model Lambda
    â””â”€â”€ README.md
```

## ğŸ§  Knowledge Base Data

**Location**: `knowledge-base/`

Contains CSV datasets from Kaggle that are automatically uploaded to S3 and ingested into the Bedrock Knowledge Base:

- **Air Quality & Water Pollution** (2021): Environmental metrics for 500+ cities
- **Cost of Living** (2018): Economic indicators for 400+ cities

These files provide the agent with factual data about cities worldwide, enabling it to answer questions about environmental conditions and economic factors.

## ğŸ§ª Test Data

**Location**: `lambda-tests/`

Contains JSON payloads for testing both Lambda functions:

- **Agent Tests**: Test the agent-based Lambda with knowledge base integration
- **Direct Tests**: Test the direct model access Lambda
- **Various Cities**: Different cities to test knowledge base coverage

## ğŸ”„ Data Flow

1. **Knowledge Base Files** â†’ S3 Bucket â†’ Bedrock Knowledge Base â†’ Vector Database
2. **Test Files** â†’ Lambda Functions â†’ Bedrock Models/Agents â†’ Responses

## ğŸ“Š Data Sources

- **Primary Source**: [Kaggle.com](https://www.kaggle.com) - World's largest data science community
- **Purpose**: Educational and demonstration use
- **Processing**: Automatic chunking and vectorization for semantic search
- **Attribution**: Properly credited in knowledge base documentation

## ğŸš€ Usage

**Automatic Deployment:**
```bash
# Knowledge base data is automatically uploaded during deployment
./scripts/deploy-complete.sh

# Test data is used by testing scripts
./scripts/test-lambda.sh both Geneva
```

**Manual Testing:**
```bash
# Use specific test payloads
aws lambda invoke --function-name your-function --payload file://data/lambda-tests/agent-berlin.json response.json
```

## ğŸ“ Adding New Data

**Knowledge Base Data:**
1. Add CSV or text files to `knowledge-base/`
2. Update Terraform configuration to include new files
3. Redeploy to upload and ingest new data

**Test Data:**
1. Add JSON files to `lambda-tests/`
2. Follow existing naming convention: `{type}-{city}.json`
3. Use with testing scripts or manual Lambda invocation

## ğŸ” Data Quality

- **Validated**: All CSV files are verified for proper formatting
- **Documented**: Each dataset includes source attribution and usage notes
- **Versioned**: Data files are tracked in version control
- **Tested**: Test payloads cover various scenarios and edge cases